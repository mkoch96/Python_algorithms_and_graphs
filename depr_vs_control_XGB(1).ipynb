{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler \n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay \n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import SGD, Nadam, Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout, SimpleRNN, BatchNormalization, GRU\n",
    "from keras import optimizers\n",
    "from keras.regularizers import l2, l1\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "import math\n",
    "import xgboost as xgb\n",
    "from xgboost import cv, XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score, cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "step = 60 \n",
    "batch_size = 16\n",
    "verbose = 1\n",
    "data_dir = \"C:/Users/086096/thesis_files\"\n",
    "segment_length = 960"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segments_and_labels(dataset_dir, segment_length, step):\n",
    "    scores = pd.read_csv(os.path.join(dataset_dir, 'scores7.csv'))\n",
    "    scores['exp_or_cont'].fillna(0, inplace=True)\n",
    "\n",
    "    segments = []\n",
    "    labels = []\n",
    "\n",
    "    for person in scores['number']:\n",
    "        p = scores[scores['number'] == person]\n",
    "        filepath = os.path.join(dataset_dir, person.split('_')[0], f'{person}.csv')\n",
    "        df_activity = pd.read_csv(filepath)\n",
    "\n",
    "        for i in range(0, len(df_activity) - segment_length, step):\n",
    "            segment = df_activity['Magnitude.mean'].values[i : i + segment_length]\n",
    "            \n",
    "            segments.append([segment])\n",
    "            labels.append(p['exp_or_cont'].values[0])\n",
    "\n",
    "    segments = np.asarray(segments)\n",
    "    segments = segments.reshape(-1, segment_length, 1)\n",
    "\n",
    "    input_shape = segments.shape[1]\n",
    "    segments = segments.reshape(segments.shape[0], input_shape).astype('float32')\n",
    "    labels = np.asarray(labels).astype('float32')\n",
    "\n",
    "    return segments, labels, input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[0.043232, 0.08168 , 0.01811 , ..., 0.062163, 0.011337, 0.010288],\n",
      "       [0.128714, 0.101046, 0.331317, ..., 0.055553, 0.031634, 0.05851 ],\n",
      "       [0.006379, 0.007886, 0.01208 , ..., 0.016275, 0.085776, 0.035873],\n",
      "       ...,\n",
      "       [0.028381, 0.112372, 0.047427, ..., 0.037865, 0.024527, 0.059238],\n",
      "       [0.073108, 0.043552, 0.070973, ..., 0.02016 , 0.026588, 0.008958],\n",
      "       [0.042946, 0.062584, 0.074234, ..., 0.006881, 0.008216, 0.00673 ]],\n",
      "      dtype=float32), array([1., 1., 1., ..., 0., 0., 0.], dtype=float32), 960)\n"
     ]
    }
   ],
   "source": [
    "print(segments_and_labels(data_dir,segment_length,step))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments, labels, input_shape = segments_and_labels(data_dir, segment_length, step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(segments, labels, test_size = 0.2, random_state = 777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGBClassifier = XGBClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16hours - 960timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits = 5, shuffle = True, random_state = 777)\n",
    "\n",
    "scores_acc = cross_validate(XGBClassifier, segments, labels, scoring = ['accuracy','precision','recall','f1'], cv=kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "[0.62356979 0.61327231 0.61670481 0.63115693 0.6139748 ]\n",
      "Mean accuracy:\n",
      "0.6197357280845922\n",
      "\n",
      "Precision:\n",
      "[0.63991323 0.66284404 0.60127932 0.64847162 0.62195122]\n",
      "Mean precision:\n",
      "0.6348918843462633\n",
      "\n",
      "Recall:\n",
      "[0.6441048  0.60208333 0.65581395 0.64847162 0.66958425]\n",
      "Mean recall:\n",
      "0.6440115902224532\n",
      "\n",
      "f1:\n",
      "[0.64200218 0.63100437 0.62736374 0.64847162 0.64488936]\n",
      "Mean f1:\n",
      "0.638746250703107\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\")\n",
    "print(scores_acc['test_accuracy'])\n",
    "print(\"Mean accuracy:\")\n",
    "print(np.mean(scores_acc['test_accuracy']))\n",
    "print()\n",
    "\n",
    "print(\"Precision:\")\n",
    "print(scores_acc['test_precision'])\n",
    "print(\"Mean precision:\")\n",
    "print(np.mean(scores_acc['test_precision']))\n",
    "print()\n",
    "\n",
    "print(\"Recall:\")\n",
    "print(scores_acc['test_recall'])\n",
    "print(\"Mean recall:\")\n",
    "print(np.mean(scores_acc['test_recall']))\n",
    "print()\n",
    "\n",
    "print(\"f1:\")\n",
    "print(scores_acc['test_f1'])\n",
    "print(\"Mean f1:\")\n",
    "print(np.mean(scores_acc['test_f1']))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "24hours - 1440timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4048,)\n",
      "(4048, 1440)\n"
     ]
    }
   ],
   "source": [
    "segment_length = 1440\n",
    "\n",
    "segments, labels, input_shape = segments_and_labels(data_dir, segment_length, step)\n",
    "\n",
    "y = labels\n",
    "X = segments\n",
    "print(y.shape)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "[0.63333333 0.66666667 0.64320988 0.6328801  0.62051916]\n",
      "Mean accuracy:\n",
      "0.6393218269773688\n",
      "\n",
      "Precision:\n",
      "[0.67370892 0.6835443  0.62389381 0.62780269 0.62527233]\n",
      "Mean precision:\n",
      "0.6468444102065279\n",
      "\n",
      "Recall:\n",
      "[0.64494382 0.72972973 0.7032419  0.68126521 0.68009479]\n",
      "Mean recall:\n",
      "0.6878550877517607\n",
      "\n",
      "f1:\n",
      "[0.65901263 0.70588235 0.66119578 0.65344224 0.65153235]\n",
      "Mean f1:\n",
      "0.6662130703361171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits = 5, shuffle = True, random_state = 777)\n",
    "\n",
    "scores_acc = cross_validate(XGBClassifier, segments, labels, scoring = ['accuracy','precision','recall','f1'], cv=kf)\n",
    "\n",
    "print(\"Accuracy:\")\n",
    "print(scores_acc['test_accuracy'])\n",
    "print(\"Mean accuracy:\")\n",
    "print(np.mean(scores_acc['test_accuracy']))\n",
    "print()\n",
    "\n",
    "print(\"Precision:\")\n",
    "print(scores_acc['test_precision'])\n",
    "print(\"Mean precision:\")\n",
    "print(np.mean(scores_acc['test_precision']))\n",
    "print()\n",
    "\n",
    "print(\"Recall:\")\n",
    "print(scores_acc['test_recall'])\n",
    "print(\"Mean recall:\")\n",
    "print(np.mean(scores_acc['test_recall']))\n",
    "print()\n",
    "\n",
    "print(\"f1:\")\n",
    "print(scores_acc['test_f1'])\n",
    "print(\"Mean f1:\")\n",
    "print(np.mean(scores_acc['test_f1']))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "48hours - 2880timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3088,)\n",
      "(3088, 2880)\n"
     ]
    }
   ],
   "source": [
    "segment_length = 2880\n",
    "\n",
    "segments, labels, input_shape = segments_and_labels(data_dir, segment_length, step)\n",
    "\n",
    "y = labels\n",
    "X = segments\n",
    "print(y.shape)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "[0.65695793 0.64239482 0.66990291 0.64505673 0.64505673]\n",
      "Mean accuracy:\n",
      "0.6518738231236855\n",
      "\n",
      "Precision:\n",
      "[0.68786127 0.65781711 0.68       0.65203762 0.65517241]\n",
      "Mean precision:\n",
      "0.666577682433761\n",
      "\n",
      "Recall:\n",
      "[0.69590643 0.67987805 0.72121212 0.65822785 0.69724771]\n",
      "Mean recall:\n",
      "0.6904944314528862\n",
      "\n",
      "f1:\n",
      "[0.69186047 0.66866567 0.7        0.65511811 0.67555556]\n",
      "Mean f1:\n",
      "0.6782399596148945\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits = 5, shuffle = True, random_state = 777)\n",
    "\n",
    "scores_acc = cross_validate(XGBClassifier, segments, labels, scoring = ['accuracy','precision','recall','f1'], cv=kf)\n",
    "\n",
    "print(\"Accuracy:\")\n",
    "print(scores_acc['test_accuracy'])\n",
    "print(\"Mean accuracy:\")\n",
    "print(np.mean(scores_acc['test_accuracy']))\n",
    "print()\n",
    "\n",
    "print(\"Precision:\")\n",
    "print(scores_acc['test_precision'])\n",
    "print(\"Mean precision:\")\n",
    "print(np.mean(scores_acc['test_precision']))\n",
    "print()\n",
    "\n",
    "print(\"Recall:\")\n",
    "print(scores_acc['test_recall'])\n",
    "print(\"Mean recall:\")\n",
    "print(np.mean(scores_acc['test_recall']))\n",
    "print()\n",
    "\n",
    "print(\"f1:\")\n",
    "print(scores_acc['test_f1'])\n",
    "print(\"Mean f1:\")\n",
    "print(np.mean(scores_acc['test_f1']))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "72hours - 4320timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2128,)\n",
      "(2128, 4320)\n"
     ]
    }
   ],
   "source": [
    "segment_length = 4320\n",
    "\n",
    "segments, labels, input_shape = segments_and_labels(data_dir, segment_length, step)\n",
    "\n",
    "y = labels\n",
    "X = segments\n",
    "print(y.shape)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "[0.6056338  0.65492958 0.65023474 0.64       0.64      ]\n",
      "Mean accuracy:\n",
      "0.6381596244131456\n",
      "\n",
      "Precision:\n",
      "[0.63306452 0.68803419 0.67948718 0.63878327 0.65185185]\n",
      "Mean precision:\n",
      "0.6582442010928459\n",
      "\n",
      "Recall:\n",
      "[0.67094017 0.68510638 0.68240343 0.74336283 0.74893617]\n",
      "Mean recall:\n",
      "0.7061497978932925\n",
      "\n",
      "f1:\n",
      "[0.65145228 0.68656716 0.68094218 0.68711656 0.6970297 ]\n",
      "Mean f1:\n",
      "0.6806215795756863\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits = 5, shuffle = True, random_state = 777)\n",
    "\n",
    "scores_acc = cross_validate(XGBClassifier, segments, labels, scoring = ['accuracy','precision','recall','f1'], cv=kf)\n",
    "\n",
    "print(\"Accuracy:\")\n",
    "print(scores_acc['test_accuracy'])\n",
    "print(\"Mean accuracy:\")\n",
    "print(np.mean(scores_acc['test_accuracy']))\n",
    "print()\n",
    "\n",
    "print(\"Precision:\")\n",
    "print(scores_acc['test_precision'])\n",
    "print(\"Mean precision:\")\n",
    "print(np.mean(scores_acc['test_precision']))\n",
    "print()\n",
    "\n",
    "print(\"Recall:\")\n",
    "print(scores_acc['test_recall'])\n",
    "print(\"Mean recall:\")\n",
    "print(np.mean(scores_acc['test_recall']))\n",
    "print()\n",
    "\n",
    "print(\"f1:\")\n",
    "print(scores_acc['test_f1'])\n",
    "print(\"Mean f1:\")\n",
    "print(np.mean(scores_acc['test_f1']))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "96hours - 5760timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1217,)\n",
      "(1217, 5760)\n"
     ]
    }
   ],
   "source": [
    "segment_length = 5760\n",
    "\n",
    "segments, labels, input_shape = segments_and_labels(data_dir, segment_length, step)\n",
    "\n",
    "y = labels\n",
    "X = segments\n",
    "print(y.shape)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "[0.69672131 0.7295082  0.67078189 0.68312757 0.68312757]\n",
      "Mean accuracy:\n",
      "0.6926533090467517\n",
      "\n",
      "Precision:\n",
      "[0.66853933 0.76821192 0.73333333 0.70588235 0.69620253]\n",
      "Mean precision:\n",
      "0.7144338928585156\n",
      "\n",
      "Recall:\n",
      "[0.8880597  0.78911565 0.73333333 0.77142857 0.79136691]\n",
      "Mean recall:\n",
      "0.7946608317975531\n",
      "\n",
      "f1:\n",
      "[0.76282051 0.77852349 0.73333333 0.73720137 0.74074074]\n",
      "Mean f1:\n",
      "0.7505238884030373\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits = 5, shuffle = True, random_state = 777)\n",
    "\n",
    "scores_acc = cross_validate(XGBClassifier, segments, labels, scoring = ['accuracy','precision','recall','f1'], cv=kf)\n",
    "\n",
    "print(\"Accuracy:\")\n",
    "print(scores_acc['test_accuracy'])\n",
    "print(\"Mean accuracy:\")\n",
    "print(np.mean(scores_acc['test_accuracy']))\n",
    "print()\n",
    "\n",
    "print(\"Precision:\")\n",
    "print(scores_acc['test_precision'])\n",
    "print(\"Mean precision:\")\n",
    "print(np.mean(scores_acc['test_precision']))\n",
    "print()\n",
    "\n",
    "print(\"Recall:\")\n",
    "print(scores_acc['test_recall'])\n",
    "print(\"Mean recall:\")\n",
    "print(np.mean(scores_acc['test_recall']))\n",
    "print()\n",
    "\n",
    "print(\"f1:\")\n",
    "print(scores_acc['test_f1'])\n",
    "print(\"Mean f1:\")\n",
    "print(np.mean(scores_acc['test_f1']))\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
